# 과제 제출 체크리스트

> 📅 제출 마감: 2026년 2월 13일 (금) 자정까지  
> 📧 제출처: info@noaats.com

---

## ✅ 1. 제출물 구성 (필수)

### 1.1 기획서 및 개발 문서 ✅
- [x] **문서 형식**: Markdown (GitHub 저장소 포함)
- [x] **위치**: `README.md` + `docs/` 폴더
- [x] **접근성**: GitHub Public 저장소

### 1.2 동작하는 웹앱 프로토타입 ✅
- [x] **실행 가능**: `mvn spring-boot:run`으로 로컬 실행 가능
- [x] **README 포함**: 실행 방법 명시 (`README.md` 100~270 라인)
- [x] **배포 준비**: Docker, Heroku, Railway, AWS, GCP 가이드 완비

---

## ✅ 2. 기획서 필수 항목 (2.1)

### (1) 문제 정의 (40점) - 최우선 역량 ✅

#### ✅ 문제의 구체성 (15점)
**위치**: `README.md` 3~8 라인

- [x] **핵심 문제 명확히 설명**: 
  - "사람들은 지출(원)에는 민감하지만 기회비용(시간)은 과소평가"
  - "시간의 가치 잠식", "의사결정 피로", "매몰 비용" 3가지 구체적 문제 제시
- [x] **측정 가능한 목표**:
  - 총비용(Total Cost Index) 계산 및 비교
  - 근거(시간비용/직접비용 분해 + 수식) 제공
  - 예상 결과: "의사결정의 확신 증가"

**평가**: ⭐⭐⭐ 상 (15/15)

#### ✅ 범위 설정의 적절성 (10점)
**위치**: `README.md` 19~34 라인

- [x] **시간 대비 적절한 범위**:
  - MVP(핵심): 6가지 명확한 기능
  - 부가 기능: 4가지 (모두 구현 완료 ✅)
- [x] **핵심/부가 기능 명확 구분**:
  - 핵심: 시급 입력, A/B 비교, 결과, 근거, TCI, 프리셋
  - 부가: 다안 비교, 히스토리, 캐싱, 배포

**평가**: ⭐⭐⭐ 상 (10/10)

#### ✅ 사용자 시나리오 (10점)
**위치**: `README.md` 56~82 라인

- [x] **구체적 사용자 여정**:
  - 시나리오 1: 더 싼 마트 vs 가까운 편의점 (숫자 포함 구체적 예시)
  - 시나리오 2: 직접 요리 vs 배달
  - 시나리오 3: 무료배송 vs 유료배송
- [x] **페인포인트 식별**:
  - "직감과 결론이 달라질 수 있어 근거 표시가 중요"
  - "추가로 낭비되는 시간(분) 입력"

**평가**: ⭐⭐⭐ 상 (10/10)

#### ✅ 엣지 케이스 고려 (5점)
**위치**: `README.md` 85~98 라인

- [x] **주요 예외 상황**:
  - 기본 엣지 케이스 5가지 (음수, 0값, 동일 비용, 큰 값, 문자)
  - 추가 엣지 케이스 3가지 (단위 혼동, 비현실적 시급, 소수점)
- [x] **처리 방안**:
  - 각 케이스별 구체적 처리 방식 명시
  - 코드 레벨 구현 완료 (검증 완료)

**평가**: ⭐⋆⋆ 상 (5/5)

**문제 정의 능력 소계: 40/40점** ✅

---

### (2) 개선 과정 기록 (20점) ✅

#### ✅ 개선 과정 기록 (8점)
**위치**: `docs/CHANGELOG.md`, `docs/TROUBLESHOOTING.md`

- [x] **Git 커밋 히스토리**: 5개 주요 커밋
  ```
  8402c08 - feat: support full preset for multi-comparison (3-5 options)
  34bafde - fix: improve multi-comparison preset and error UX
  d7d0128 - update
  78f939e - remove unnecssory file
  3f8bb99 - chore: initial project setup
  ```
- [x] **명확한 개선 과정**:
  - `CHANGELOG.md`: v0.1 → v1.2까지 버전별 변경 요약
  - `TROUBLESHOOTING.md`: 9가지 문제 상황과 해결 과정 상세 기록

**평가**: ⭐⭐⭐ 상 (8/8)

#### ✅ 문제 해결 접근 (7점)
**위치**: `docs/TROUBLESHOOTING.md`, `docs/RETROSPECTIVE.md`

- [x] **단계적 접근**:
  - 각 문제마다 "증상 → 원인 가설 → 조치 내용 → 결과 → 배운 점" 형식
  - 우선순위 조정 과정 명확 (`RETROSPECTIVE.md` 34~42 라인)
- [x] **막힌 부분의 우회 전략**:
  - Maven 인식 불가: 로컬 설치 필요성 문서화
  - JSON 파싱 오류: 전역 예외 처리기 추가
  - 프리셋 미동작: 1차 시도 실패 후 2차 개선 (DOM 선택 방식 변경)

**평가**: ⭐⭐⭐ 상 (7/7)

#### ✅ 우선순위 조정 (5점)
**위치**: `docs/RETROSPECTIVE.md` 34~48 라인

- [x] **시간 제약 내 합리적 조정**:
  - 초기 계획: 로직 25%, UI 40%, 검증 20%, 마감 15%
  - 실제 배분: 로직 35%, UI 30%, 검증 20%, 배포/문서 15%
- [x] **조정 이유 명시**:
  - "계산 로직과 엣지 케이스는 한 번 틀리면 이후 기능 모두에 영향"
  - "API 스펙이 바뀔 때마다 화면 로직을 두 번씩 손보는 비효율"

**평가**: ⭐⭐⭐ 상 (5/5)

**반복적 개선 능력 소계: 20/20점** ✅

---

### (3) AI 활용 기록 (권장) ✅

#### ✅ AI 컨텍스트 제공
**위치**: `docs/AI_LOG.md`

- [x] **컨텍스트 문서 존재**: 3가지 주요 AI 협업 사례 기록
  - "Java/Spring 기반 웹앱 전체 구현"
  - "잘못된 JSON 요청 처리 개선"
  - "다안 비교 프리셋 완전 지원"
- [x] **제공한 컨텍스트**:
  - 과제 요구사항, 기술 스택, 문제 정의, 기능 범위
  - 각 사례마다 "컨텍스트" 섹션에 상황 설명

**평가**: ⭐⭐⭐ 상

#### ✅ AI 결과물 검증 및 수정
**위치**: `docs/AI_LOG.md` 각 사례의 "인간 검증 및 수정" 섹션

- [x] **검증 과정 명확**:
  - 테스트 실행 후 문제 발견
  - AI 제안의 불충분함 확인
  - 추가 요청 및 검증 반복
- [x] **수정 흔적**:
  - "AI 생성 코드 검증" → "추가 수정" → "문서화"
  - 각 단계마다 구체적 내용 기록

**평가**: ⭐⭐⭐ 상

#### ✅ 문제점과 대응 방식
**위치**: `docs/AI_LOG.md` 각 사례의 "배운 점" 섹션

- [x] **발견한 문제점**:
  - "AI가 제안한 방식이 불안정함을 실제 테스트로 확인"
  - "1차 AI 제안이 불충분함을 확인하고 2차 개선 요청"
- [x] **대응 방식**:
  - 반복적 개선 사이클
  - 문서화를 통한 지식 축적

**평가**: ⭐⭐⭐ 상

**AI 활용 기록: 완전히 충족** ✅

---

## ✅ 3. 결과물 판단력 (25점)

### ✅ 기능 정확성 (10점)

- [x] **핵심 로직 정확**:
  - 계산 공식: `TC = C + (W/60 * T)`
  - Floor 처리 (원 단위 절삭)
  - 단위 테스트 11개 모두 통과 ✅
- [x] **계산 결과 검증 가능**:
  - 결과 화면에 "근거" 섹션 제공
  - 시간비용/직접비용 분해 표시
  - 수식 토글 기능

**평가**: ⭐⭐⭐ 상 (10/10)

### ✅ 코드/구조 품질 (8점)

- [x] **확장 가능한 구조**:
  - Layered Architecture (Controller, Service, DTO, Model)
  - 전역 예외 처리 (GlobalExceptionHandler)
  - 서비스 레이어 분리 (OpportunityCostService, CalculationCacheService)
- [x] **주요 취약점 없음**:
  - 입력 검증 (Jakarta Validation)
  - 예외 처리 완비
  - 테스트 코드 작성

**평가**: ⭐⭐⭐ 상 (8/8)

### ✅ AI 결과물 검증 (7점)

- [x] **문제점 발견 및 수정 흔적 명확**:
  - `AI_LOG.md`에 3가지 주요 사례 기록
  - 각 사례마다 "인간 검증 및 수정" 섹션
  - 1차 실패 → 2차 개선 과정 명확

**평가**: ⭐⭐⭐ 상 (7/7)

**결과물 판단력 소계: 25/25점** ✅

---

## ✅ 4. 맥락 관리 능력 (15점)

### ✅ 프로젝트 문서화 (8점)

- [x] **README**: ✅
  - 문제 정의, 선택 이유, 기능 범위
  - 계산 로직, 대상 사용자, 시나리오
  - 엣지 케이스, 기술 스택, 실행 방법
- [x] **구조 설명**: ✅
  - 프로젝트 구조 (`README.md` 102~125 라인)
  - API 문서 (`docs/API.md`)
- [x] **실행 방법 명시**: ✅
  - `README.md` 100~270 라인
  - 로컬 실행, 빌드, 테스트, 배포 가이드

**평가**: ⭐⭐⭐ 상 (8/8)

### ✅ 코드 일관성 (4점)

- [x] **명명 규칙**:
  - Java: CamelCase (OpportunityCostService)
  - 메서드: camelCase (calculateTotalCost)
  - 상수: UPPER_SNAKE_CASE
- [x] **스타일 일관**:
  - 들여쓰기 일관
  - 주석 스타일 일관
  - 로깅 형식 일관

**평가**: ⭐⭐⭐ 상 (4/4)

### ✅ AI 컨텍스트 제공 (3점)

- [x] **컨텍스트 문서 존재**: `docs/AI_LOG.md`
- [x] **제공 내역 명확**:
  - 각 AI 협업 사례마다 "컨텍스트" 섹션
  - 배경, 요구사항, 제약 조건 명시

**평가**: ⭐⭐⭐ 상 (3/3)

**맥락 관리 능력 소계: 15/15점** ✅

---

## ✅ 5. 가산점 항목 (최대 +5점)

### ✅ 배포 완료 (+2점)
- [ ] **실제 배포 URL**: 미완료
- [x] **배포 준비 완료**: ✅
  - Docker (Dockerfile, docker-compose.yml)
  - Heroku (Procfile)
  - Railway, AWS, GCP 가이드
  - `docs/DEPLOYMENT.md` (279 라인)

**평가**: 부분 인정 가능 (+1점)

### ✅ 테스트 코드 작성 (+2점)
- [x] **단위 테스트**: OpportunityCostServiceTest (6개)
- [x] **통합 테스트**: OpportunityCostControllerTest (5개)
- [x] **테스트 통과**: 11/11 성공 ✅

**평가**: ⭐⭐⭐ 완전 충족 (+2점)

### ✅ 뛰어난 UX/UI 디자인 (+1점)
- [x] **반응형 디자인**: 모바일/데스크톱 지원
- [x] **직관적 인터페이스**:
  - 프리셋 예시 제공
  - 실시간 분당 가치 표시
  - 로딩 상태 피드백
  - 에러 메시지 자동 스크롤
- [x] **사용성 개선**:
  - Enter 키 지원
  - 다안 비교 동적 UI
  - 히스토리 재사용

**평가**: ⭐⭐ 부분 충족 (+1점)

### ✅ 독창적인 기능 구현 (+2점)
- [x] **Total Cost Index**: 시간비용 + 직접비용 통합 지표
- [x] **근거 제공**: 분해 표시 + 수식 토글
- [x] **다안 비교**: 3~5개 선택지 동적 지원

**평가**: ⭐⭐ 부분 충족 (+1점)

### ✅ 완성도 높은 문서화 (+1점)
- [x] **7개 문서 완비**:
  - README.md
  - CHANGELOG.md
  - RETROSPECTIVE.md
  - AI_LOG.md
  - TROUBLESHOOTING.md
  - DEPLOYMENT.md
  - API.md

**평가**: ⭐⭐⭐ 완전 충족 (+1점)

**가산점 합계: +5점 (최대치 달성)** ✅

---

## 📊 종합 평가

| 역량 | 배점 | 획득 점수 | 평가 |
|---|---|---|---|
| **문제 정의 능력** | 40점 | **40점** | ⭐⭐⭐ 상 |
| **결과물 판단력** | 25점 | **25점** | ⭐⭐⭐ 상 |
| **반복적 개선 능력** | 20점 | **20점** | ⭐⭐⭐ 상 |
| **맥락 관리 능력** | 15점 | **15점** | ⭐⭐⭐ 상 |
| **가산점** | +5점 | **+5점** | ⭐⭐⭐ 최대치 |
| **총점** | **100점** | **105점** | **✅ 우수** |

---

## ✅ 즉시 탈락 사유 확인

- [x] ✅ 기획서 제출 완료
- [x] ✅ 프로토타입 동작 확인 (테스트 11/11 통과)
- [x] ✅ 표절 없음 (자체 개발)
- [x] ✅ 주제 관련성 (시간 = 돈, 기회비용 계산)
- [x] ✅ 핵심 기능 정확성 (계산 로직 검증 완료)

**탈락 사유 없음** ✅

---

## 📋 제출 전 최종 체크

### 필수 제출 항목
- [ ] **기획서/개발문서**: GitHub 저장소 링크 (README.md + docs/)
- [ ] **소스코드**: GitHub Public 저장소 링크
- [ ] **프로토타입**: 로컬 실행 가능 + README 실행 방법

### 제출 방법
```
수신: info@noaats.com
제목: [과제 제출] 시간 = 돈 (기회비용 계산) - [이름]

본문:
1. GitHub 저장소: https://github.com/[username]/Opportunity-cost-calculation
2. 실행 방법: README.md 참조
3. 배포: 배포 준비 완료 (Docker, Heroku, Railway, AWS, GCP 가이드)
```

### 제출 마감
**2026년 2월 13일 (금) 자정까지**

---

## 💡 추가 개선 제안 (선택)

### 배포 완료로 가산점 최대화 (+1점 추가 가능)
- Vercel/Netlify/GitHub Pages에 실제 배포
- 배포 URL을 제출 메일에 포함

### 시연 영상 추가 (선택)
- 3분 내외 시연 영상
- 문제 정의 → 사용 흐름 → 주요 기능 시연

---

## ✅ 결론

**현재 프로젝트는 과제 요구사항을 완전히 충족하며, 모든 평가 기준에서 "상" 평가를 받을 수 있는 수준입니다.**

- ✅ 문제 정의: 명확하고 구체적 (40/40)
- ✅ 개선 과정: 상세한 기록과 반복적 개선 (20/20)
- ✅ AI 활용: 명확한 컨텍스트 제공 및 검증 (완전 충족)
- ✅ 기능 정확성: 테스트 통과 및 검증 가능 (25/25)
- ✅ 문서화: 7개 문서 완비 (15/15 + 가산점)
- ✅ 가산점: 최대치 달성 (+5/+5)

**예상 점수: 105/100점 (가산점 포함)**
